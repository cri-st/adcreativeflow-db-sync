# DocumentaciÃ³n TÃ©cnica: AdCreativeFlow DB Sync

## ğŸ“‹ DescripciÃ³n General

**AdCreativeFlow DB Sync** es un servicio serverless implementado como un **Cloudflare Worker** diseÃ±ado para sincronizar datos masivos desde **Google BigQuery** (origen) hacia **Supabase/PostgreSQL** (destino).

El sistema funciona de manera autÃ³noma mediante cron triggers (programados cada 6 horas) o puede ser invocado manualmente vÃ­a API. Su objetivo principal es mantener una rÃ©plica actualizada de los datos analÃ­ticos para su uso en aplicaciones frontend, manejando tanto inserciones/actualizaciones como la eliminaciÃ³n de registros obsoletos.

---

## ğŸ— Arquitectura

El proyecto estÃ¡ construido sobre las siguientes tecnologÃ­as:

- **Runtime**: Cloudflare Workers (Edge Computing).
- **Framework**: Hono (Servidor web ligero y tipado).
- **Almacenamiento de Estado**: Cloudflare KV (Key-Value Store) para configuraciones y cursores de paginaciÃ³n.
- **Origen de Datos**: Google BigQuery (API REST con autenticaciÃ³n JWT vÃ­a Service Account).
- **Destino de Datos**: Supabase (Cliente JS oficial).
- **Dashboard**: Interfaz web estÃ¡tica (HTML/JS) servida desde el mismo Worker para gestionar configuraciones.

```mermaid
graph TD
    subgraph Cloudflare Worker
        API[Hono API]
        Cron[Cron Trigger]
        SyncEngine[Sync Engine]
        Dashboard[UI Dashboard]
    end

    subgraph "External Services"
        BQ[(Google BigQuery)]
        Supabase[(Supabase DB)]
        KV[(Cloudflare KV)]
    end

    Cron -->|Every 6h| SyncEngine
    API -->|Manual Trigger| SyncEngine
    API -->|Manage Config| KV
    
    SyncEngine -->|1. Fetch State| KV
    SyncEngine -->|2. Fetch Data| BQ
    SyncEngine -->|3. Upsert Data| Supabase
    SyncEngine -->|4. Delete Old Rows| Supabase
    SyncEngine -->|5. Save State| KV
```

---

## âš™ï¸ Flujo de SincronizaciÃ³n

El proceso de sincronizaciÃ³n (`handleSync`) es el nÃºcleo del sistema y sigue un flujo robusto diseÃ±ado para manejar grandes volÃºmenes de datos y evitar timeouts.

### 1. InicializaciÃ³n y ValidaciÃ³n de Esquema
Al iniciar un trabajo (Job):
1. **Fetch Metadata**: Obtiene el esquema de la tabla origen en BigQuery.
2. **Sync Schema**:
   - Crea la tabla en Supabase si no existe.
   - Detecta diferencias de columnas (nuevas o eliminadas).
   - Aplica cambios DDL (`ALTER TABLE`) automÃ¡ticamente para mantener ambos esquemas idÃ©nticos.
3. **ValidaciÃ³n**: Verifica que las `upsertColumns` (claves Ãºnicas) existan y sean vÃ¡lidas.

### 2. SincronizaciÃ³n Incremental (Insert/Update)
El sistema utiliza una estrategia de paginaciÃ³n por cursores para procesar datos eficientemente:

- **Batching**: Procesa registros en lotes de 5,000 filas desde BigQuery.
- **Sub-batching**: Inserta en Supabase en sub-lotes de 2,500 filas para respetar lÃ­mites de tamaÃ±o de payload.
- **Upsert**: Utiliza la operaciÃ³n `UPSERT` (Insertar o Actualizar) basada en las columnas clave definidas (`upsertColumns`).
- **Persistencia de Estado**: Guarda el progreso en KV. Si el Worker se detiene por lÃ­mites de tiempo (15 min), la prÃ³xima ejecuciÃ³n retoma exactamente donde quedÃ³ usando el cursor compuesto (`incrementalColumn` + `tieBreaker`).

### 3. DetecciÃ³n y EliminaciÃ³n de Borrados (Delete Phase) ğŸ†•
Esta fase se ejecuta **solo en el Ãºltimo lote** de la sincronizaciÃ³n, cuando ya no hay mÃ¡s datos nuevos que traer de BigQuery. Su objetivo es mantener la consistencia eliminando registros que ya no existen en el origen.

#### Estrategia "Hybrid Approach"
DiseÃ±ada para soportar tablas de hasta 1 millÃ³n de filas sin exceder los lÃ­mites de memoria (128MB) o CPU del Worker.

1. **Fase de ObtenciÃ³n (Fetch)**:
   - Descarga **todos** los IDs (`upsertColumns`) de BigQuery (consulta ligera, ignora filtros incrementales).
   - Descarga **todos** los IDs de Supabase mediante paginaciÃ³n (bloques de 10,000 registros).

2. **Fase de ComparaciÃ³n (Compare)**:
   - Carga los IDs en memoria usando estructuras `Set` de JavaScript para una comparaciÃ³n O(n) rÃ¡pida.
   - Identifica los IDs que existen en Supabase pero **NO** en BigQuery.
   - Serializa claves compuestas usando JSON para garantizar precisiÃ³n (ej: `["id1", "2024-01-01"]`).

3. **Fase de EliminaciÃ³n (Delete)**:
   - Ejecuta eliminaciones fÃ­sicas (`DELETE`) en Supabase.
   - Procesa en lotes de **200 registros** para evitar lÃ­mites de longitud de URL en la API de Supabase.

#### Mecanismos de Seguridad (Circuit Breakers)
Para evitar desastres (como borrar toda una tabla por error), el sistema incluye protecciones estrictas:

- â›” **Abortar si BigQuery = 0**: Si BigQuery retorna 0 filas, se asume un error de conexiÃ³n o configuraciÃ³n y se aborta el proceso de borrado.
- â›” **LÃ­mite del 50%**: Si el sistema detecta que debe eliminar mÃ¡s del 50% de la tabla de destino, aborta la operaciÃ³n y lanza un error, asumiendo que es una anomalÃ­a que requiere revisiÃ³n manual.
- â­ï¸ **Skip en Primer Sync**: Si la tabla de Supabase estÃ¡ vacÃ­a, se salta esta fase para optimizar recursos.

```mermaid
sequenceDiagram
    participant BQ as BigQuery
    participant W as Worker (Sync)
    participant SB as Supabase
    participant KV as KV State

    Note over W: Start Batch
    W->>KV: Get Last Cursor
    W->>BQ: Fetch Data (Limit 5000)
    activate BQ
    BQ-->>W: Return Rows
    deactivate BQ
    
    W->>SB: UPSERT Batch (2500 rows)
    W->>SB: UPSERT Batch (2500 rows)

    alt More Data Available (HasMore = true)
        W->>KV: Save Cursor State
        Note over W: End Batch (Continue later)
    else No More Data (HasMore = false)
        Note over W: Final Batch - Start Delete Phase
        W->>BQ: Fetch ALL IDs (upsertColumns)
        W->>SB: Fetch ALL IDs (upsertColumns)
        Note over W: Compare Sets (Memory)
        
        loop Batched Deletes
            W->>SB: DELETE Removed Rows (Batch 200)
        end
        
        W->>KV: Clear Cursor State
        Note over W: Job Complete
    end
```

---

## ğŸ›¡ï¸ Seguridad y AutenticaciÃ³n

- **API Security**: Todos los endpoints del Worker estÃ¡n protegidos por un `Bearer Token` (`SYNC_API_KEY`).
- **BigQuery Auth**: Utiliza una Service Account de Google. Genera y firma JWTs (JSON Web Tokens) internamente usando la librerÃ­a `jose` para autenticarse con la API de Google Cloud.
- **Supabase Auth**: Utiliza la URL y Service Role Key de Supabase para tener permisos de administraciÃ³n (DDL y manipulaciÃ³n de datos).

---

## ğŸ“Š ConfiguraciÃ³n de Jobs

Los trabajos se configuran mediante objetos JSON almacenados en KV (`SYNC_CONFIGS`).

**Estructura del JSON:**

```json
{
  "id": "job_marketing_data",
  "name": "Marketing Data Sync",
  "enabled": true,
  "bigquery": {
    "projectId": "mi-proyecto-gcp",
    "datasetId": "analytics",
    "tableOrView": "marketing_kpis",
    "incrementalColumn": "updated_at", // Opcional: para sync incremental
    "forceStringFields": ["ad_id"]     // Opcional: para preservar precisiÃ³n de IDs largos
  },
  "supabase": {
    "tableName": "marketing_kpis",
    "upsertColumns": ["ad_id", "date"] // Clave Ãºnica compuesta
  }
}
```

---

## ğŸš¦ Monitoreo y Logs

El sistema genera logs estructurados que se almacenan en KV (`SYNC_LOGS`) y son visibles desde el dashboard.

- **Niveles**: INFO, SUCCESS, WARNING, ERROR, DEBUG.
- **Resumen Final**: Al terminar, genera un resumen legible:
  > *"15,000 rows synced, 320 deleted in 2m 45s"*

---

## ğŸš€ Despliegue

```bash
# Instalar dependencias
npm install

# Desarrollo local
npm run dev

# Desplegar a producciÃ³n
npm run deploy
```
